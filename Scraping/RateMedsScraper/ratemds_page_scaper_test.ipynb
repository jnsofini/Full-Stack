{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Craping Notebook\n",
    "The scaper here will focus on doctors in Saskatchewan. However, it can be readily adapted to any region in the world by adapting the url. Our focus will be pages in https://www.ratemds.com/best-doctors/sk. ,A combination of these pages sends relatively a small number of requests. A request is what happens whenever web page is accessed. A `request` of the content of a page from the server. The more requests we make, the longer our script will need to run, and the greater the strain on the server.\n",
    "\n",
    "One way to get all the data we need is to compile a list of specialties, and use it to access the web page.\n",
    "If we go to the [ratemds](www.ratemds.com/best-doctors/sk/regina) site we can see that the specialties are listed. Upon exploring it, we not that each page for any specialty displays upto 10 doctors and their raitings.\n",
    "The data will be restricted to to medical personels with atleast a review.\n",
    "\n",
    "### Identifying the URL structure\n",
    "Our challenge now is to make sure we understand the logic of the URL as the pages we want to scrape change. This will help us to extract the parameters we wants. At the moment, we are going to extract the __name, specialty, ratings, votes, gender__. The votes refer to the number of people who gave reviews, and the others are self expllanatory. \n",
    "\n",
    "Lets further limit ourselves to doctors in the Regina region. The url in this case is <em>https://www.ratemds.com/best-doctors/sk/regina/ </em>. We used url request\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "url = 'https://www.ratemds.com/best-doctors/sk/regina/'\n",
    "response = get(url)\n",
    "print(response.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the HTML structure of a single page\n",
    "\n",
    "The first line of response.text indicates that the server sent us an HTML document. The document describes comes with the overall structure of that web page, along with its specific unique content.\n",
    "Upon inspection, we can notice that the pages we want to scrape have the same overall structure leading to the same HTML structure. So, one task in the script is for it to understand the HTML structure of only one page. The browser’s Developer Tools can be used.\n",
    "\n",
    "Each page has 11 health pracitoner and we can navigate the pages by clicking on each of the page numers displayed underneath. To parse our HTML document and extract the 11 health practitioners div containers, Python BeautifulSoup module is used.\n",
    "  -  Import BeautifulSoup class creator from the package bs4.\n",
    "  -  Parse response.text by creating a BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "type(html_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_container = html_soup.find_all('div', class_ = 'search-item doctor-profile')\n",
    "print(type(doctor_container))\n",
    "print(len(doctor_container))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select only the first container, and extract each item of interest, including the __name, specialty, ratings, score, sex__\n",
    "\n",
    "##### a. Name\n",
    "Lets concentrate on the first item. Using the Devtools we note that the name is contained within an anchor tag `<a>` inside the`doctor_container[0]` object. To extract it us the command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_container[0].a.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Specialty\n",
    "This data is stored within the `<div>` tag below the `<a>` that contains the name. Dot notation will only access the first div element, so a search by the distinctive mark of the second `<div>` using the `find()` method. Note, `find()` is equivalent to `find_all(limit = 1)`, with limit argument retricting the output to the first match. The distinguishing mark consists of the values __search-item-specialty__ assigned to the class attribute. \n",
    "To extract thisus the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_container[0].find('div', class_ = 'search-item-specialty').a.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Rating\n",
    "Just like above, it is found in a tag, this time specifically `<span>`. The `find()` method with the distinguishing mark consists of the values __star-rating__ assigned to the class attribute. The ratings is present inside a dict that is access via ,title'. Extract it using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_container[0].find('span', class_ = 'star-rating')['title'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Votes\n",
    "The votes are present in a  `<div>` tage identified by values __star-rating-count__ . Using the `find()` method, the text can be extract it using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_container[0].find('div', class_ = \"star-rating-count\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Gender\n",
    "The gender can be extracted in multiple ways including navigating to the individual doctor's profile and extracting it. Here we extract it from the profile picture. This is achieved via the `find()` method to an  `<src>` tag identified by values __search-item-image__ . The following will return the first letter of the sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sexurl =  doctor_container[0].find('img', class_=\"search-item-image\")['src']      \n",
    "os.path.dirname(sexurl)[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the scraped data in\n",
    "names = []\n",
    "specialty = []\n",
    "ratings = []\n",
    "ratings_count = []\n",
    "gender = []\n",
    "\n",
    "#Extract data from individual doctor container\n",
    "for container in doctor_container:\n",
    "    # If the doctor has ratings, then extract:\n",
    "    rating = float(container.find('span', class_ = 'star-rating')['title'])\n",
    "    if rating != 0:        \n",
    "        names.append(container.a.get_text())   #add the name\n",
    "        #specialty\n",
    "        special = container.find('div', class_ = 'search-item-specialty').a.get_text()\n",
    "        specialty.append(special)\n",
    "        #rating\n",
    "        ratings.append(rating)\n",
    "        #Number of ratings\n",
    "        num_ratings = container.find('div', class_ = \"star-rating-count\").get_text()\n",
    "        ratings_count.append(int(num_ratings.split()[0]))\n",
    "        #gender\n",
    "        sexurl =  container.find('img', class_=\"search-item-image\")['src']       \n",
    "        gender.append(os.path.dirname(sexurl)[44])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the data collected so far. Pandas makes it easy for us to see whether we’ve scraped our data successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "page_1 = pd.DataFrame({'Name': names,\n",
    "                        'Specialty': specialty,\n",
    "                        'Ratings': ratings,\n",
    "                        'Rates': ratings_count,\n",
    "                        'Gender': gender\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The script for multiple pages\n",
    "At this point follow the markdown file or the use the .py script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
